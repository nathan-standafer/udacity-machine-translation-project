{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "## Machine Translation Project\n",
    "In this notebook, sections that end with **'(IMPLEMENTATION)'** in the header indicate that the following blocks of code will require additional functionality which you must provide. Please be sure to read the instructions carefully!\n",
    "\n",
    "## Introduction\n",
    "In this notebook, you will build a deep neural network that functions as part of an end-to-end machine translation pipeline. Your completed pipeline will accept English text as input and return the French translation.\n",
    "\n",
    "- **Preprocess** - You'll convert text to sequence of integers.\n",
    "- **Models** Create models which accepts a sequence of integers as input and returns a probability distribution over possible translations. After learning about the basic types of neural networks that are often used for machine translation, you will engage in your own investigations, to design your own model!\n",
    "- **Prediction** Run the model on English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%aimport helper, tests\n",
    "%autoreload 1\n",
    "\n",
    "!pip install keras #only needed when running from tensorflow docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "import project_tests as tests\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify access to the GPU\n",
    "The following test applies only if you expect to be using a GPU, e.g., while running in a Udacity Workspace or using an AWS instance with GPU support. Run the next cell, and verify that the device_type is \"GPU\".\n",
    "- If the device is not GPU & you are running from a Udacity Workspace, then save your workspace with the icon at the top, then click \"enable\" at the bottom of the workspace.\n",
    "- If the device is not GPU & you are running from an AWS instance, then refer to the cloud computing instructions in the classroom to verify your setup steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version: 2.4.3\n",
      "tensorflow version: 2.3.0\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10730224504940025092\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7040116858334987708\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3734509023726442669\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10144673984\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14760785701647995299\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:07:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "print(\"keras version: {}\".format(keras.__version__))\n",
    "print(\"tensorflow version: {}\".format(tf.__version__))\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We begin by investigating the dataset that will be used to train and evaluate your pipeline.  The most common datasets used for machine translation are from [WMT](http://www.statmt.org/).  However, that will take a long time to train a neural network on.  We'll be using a dataset we created for this project that contains a small vocabulary.  You'll be able to train your model in a reasonable time with this dataset.\n",
    "### Load Data\n",
    "The data is located in `data/small_vocab_en` and `data/small_vocab_fr`. The `small_vocab_en` file contains English sentences with their French translations in the `small_vocab_fr` file. Load the English and French data from these files from running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded\n"
     ]
    }
   ],
   "source": [
    "# Load English data\n",
    "english_sentences = helper.load_data('data/small_vocab_en')\n",
    "# Load French data\n",
    "french_sentences = helper.load_data('data/small_vocab_fr')\n",
    "\n",
    "print('Dataset Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files\n",
    "Each line in `small_vocab_en` contains an English sentence with the respective translation in each line of `small_vocab_fr`.  View the first two lines from each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sentences: 137861\n",
      "small_vocab_en Line 1:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "small_vocab_fr Line 1:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "small_vocab_en Line 2:  the united states is usually chilly during july , and it is usually freezing in november .\n",
      "small_vocab_fr Line 2:  les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n"
     ]
    }
   ],
   "source": [
    "print(\"total sentences: {}\".format(len(english_sentences)))\n",
    "\n",
    "for sample_i in range(2):\n",
    "    print('small_vocab_en Line {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
    "    print('small_vocab_fr Line {}:  {}'.format(sample_i + 1, french_sentences[sample_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the sentences, you can see they have been preprocessed already.  The puncuations have been delimited using spaces. All the text have been converted to lowercase.  This should save you some time, but the text requires more preprocessing.\n",
    "### Vocabulary\n",
    "The complexity of the problem is determined by the complexity of the vocabulary.  A more complex vocabulary is a more complex problem.  Let's look at the complexity of the dataset we'll be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1823250 English words.\n",
      "227 unique English words.\n",
      "10 Most common words in the English dataset:\n",
      "\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n",
      "\n",
      "1961295 French words.\n",
      "355 unique French words.\n",
      "10 Most common words in the French dataset:\n",
      "\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n",
      "\n",
      "227 unique english words using a normal loop.\n"
     ]
    }
   ],
   "source": [
    "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
    "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n",
    "\n",
    "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
    "print('{} unique English words.'.format(len(english_words_counter)))\n",
    "print('10 Most common words in the English dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "print('{} French words.'.format(len([word for sentence in french_sentences for word in sentence.split()])))\n",
    "print('{} unique French words.'.format(len(french_words_counter)))\n",
    "print('10 Most common words in the French dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')\n",
    "\n",
    "english_words_set = set()\n",
    "\n",
    "for sentence in english_sentences:\n",
    "    for word in sentence.split():\n",
    "        english_words_set.add(word)\n",
    "print (\"\\n{} unique english words using a normal loop.\".format(len(english_words_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, _Alice's Adventures in Wonderland_ contains 2,766 unique words of a total of 15,500 words.\n",
    "## Preprocess\n",
    "For this project, you won't use text data as input to your model. Instead, you'll convert the text into sequences of integers using the following preprocess methods:\n",
    "1. Tokenize the words into ids\n",
    "2. Add padding to make all the sequences the same length.\n",
    "\n",
    "Time to start preprocessing the data...\n",
    "### Tokenize (IMPLEMENTATION)\n",
    "For a neural network to predict on text data, it first has to be turned into data it can understand. Text data like \"dog\" is a sequence of ASCII character encodings.  Since a neural network is a series of multiplication and addition operations, the input data needs to be number(s).\n",
    "\n",
    "We can turn each character into a number or each word into a number.  These are called character and word ids, respectively.  Character ids are used for character level models that generate text predictions for each character.  A word level model uses word ids that generate text predictions for each word.  Word level models tend to learn better, since they are lower in complexity, so we'll use those.\n",
    "\n",
    "Turn each sentence into a sequence of words ids using Keras's [`Tokenizer`](https://keras.io/preprocessing/text/#tokenizer) function. Use this function to tokenize `english_sentences` and `french_sentences` in the cell below.\n",
    "\n",
    "Running the cell will run `tokenize` on sample data and show output for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n",
      "\n",
      "Sequence 1 in x\n",
      "  Input:  The quick brown fox jumps over the lazy dog .\n",
      "  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
      "Sequence 2 in x\n",
      "  Input:  By Jove , my quick study of lexicography won a prize .\n",
      "  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
      "Sequence 3 in x\n",
      "  Input:  This is a short sentence .\n",
      "  Output: [18, 19, 3, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "    \"\"\"\n",
    "    Tokenize x\n",
    "    :param x: List of sentences/strings to be tokenized\n",
    "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    x_tk = Tokenizer()\n",
    "    x_tk.fit_on_texts(x)\n",
    "    \n",
    "    #return None, None\n",
    "    return x_tk.texts_to_sequences(x), x_tk\n",
    "\n",
    "tests.test_tokenize(tokenize)\n",
    "\n",
    "# Tokenize Example output\n",
    "text_sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog .',\n",
    "    'By Jove , my quick study of lexicography won a prize .',\n",
    "    'This is a short sentence .']\n",
    "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)\n",
    "print()\n",
    "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding (IMPLEMENTATION)\n",
    "When batching the sequence of word ids together, each sequence needs to be the same length.  Since sentences are dynamic in length, we can add padding to the end of the sequences to make them the same length.\n",
    "\n",
    "Make sure all the English sequences have the same length and all the French sequences have the same length by adding padding to the **end** of each sequence using Keras's [`pad_sequences`](https://keras.io/preprocessing/sequence/#pad_sequences) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1 in x\n",
      "  Input:  [1 2 4 5 6 7 1 8 9]\n",
      "  Output: [1 2 4 5 6 7 1 8 9 0]\n",
      "Sequence 2 in x\n",
      "  Input:  [10 11 12  2 13 14 15 16  3 17]\n",
      "  Output: [10 11 12  2 13 14 15 16  3 17]\n",
      "Sequence 3 in x\n",
      "  Input:  [18 19  3 20 21]\n",
      "  Output: [18 19  3 20 21  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "def pad(x, length=None):\n",
    "    \"\"\"\n",
    "    Pad x\n",
    "    :param x: List of sequences.\n",
    "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
    "    :return: Padded numpy array of sequences\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    padded_sentences = pad_sequences(x, maxlen=length, padding='post') \n",
    "    return padded_sentences\n",
    "\n",
    "tests.test_pad(pad)\n",
    "\n",
    "# Pad Tokenized output\n",
    "test_pad = pad(text_tokenized)\n",
    "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(np.array(token_sent)))\n",
    "    print('  Output: {}'.format(pad_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Pipeline\n",
    "Your focus for this project is to build neural network architecture, so we won't ask you to create a preprocess pipeline.  Instead, we've provided you with the implementation of the `preprocess` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n",
      "Max English sentence length: 15\n",
      "Max French sentence length: 21\n",
      "English vocabulary size: 199\n",
      "French vocabulary size: 344\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    Preprocess x and y\n",
    "    :param x: Feature List of sentences\n",
    "    :param y: Label List of sentences\n",
    "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
    "    \"\"\"\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
    "\n",
    "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n",
    "    preprocess(english_sentences, french_sentences)\n",
    "    \n",
    "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
    "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
    "english_vocab_size = len(english_tokenizer.word_index)\n",
    "french_vocab_size = len(french_tokenizer.word_index)\n",
    "\n",
    "print('Data Preprocessed')\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max French sentence length:\", max_french_sequence_length)\n",
    "print(\"English vocabulary size:\", english_vocab_size)\n",
    "print(\"French vocabulary size:\", french_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "In this section, you will experiment with various neural network architectures.\n",
    "You will begin by training four relatively simple architectures.\n",
    "- Model 1 is a simple RNN\n",
    "- Model 2 is a RNN with Embedding\n",
    "- Model 3 is a Bidirectional RNN\n",
    "- Model 4 is an optional Encoder-Decoder RNN\n",
    "\n",
    "After experimenting with the four simple architectures, you will construct a deeper architecture that is designed to outperform all four models.\n",
    "### Ids Back to Text\n",
    "The neural network will be translating the input to words ids, which isn't the final form we want.  We want the French translation.  The function `logits_to_text` will bridge the gab between the logits from the neural network to the French translation.  You'll be using this function to better understand the output of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`logits_to_text` function loaded.\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "print('`logits_to_text` function loaded.')\n",
    "\n",
    "def tokens_to_text(tokens, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn tokens into words\n",
    "    :param tokens: numpy array of tokens.  shape (1,length,1)\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the tokens\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return_text = \"\"\n",
    "    \n",
    "    for token in tokens[0]:\n",
    "        if isinstance(token, np.ndarray):\n",
    "            return_text += index_to_words[token[0]]\n",
    "        else:\n",
    "            return_text += index_to_words[token]\n",
    "        return_text += ' '\n",
    "    \n",
    "    return return_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: RNN (IMPLEMENTATION)\n",
    "![RNN](images/rnn.png)\n",
    "A basic RNN model is a good baseline for sequence data.  In this model, you'll build a RNN that translates English to French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: (137861, 21, 1)\n",
      "output_sequence_length: 21\n",
      "english_vocab_size: 199\n",
      "french_vocab_size: 344\n",
      "\n",
      "\n",
      "input_shape: (137861, 21, 1)\n",
      "output_sequence_length: 21\n",
      "english_vocab_size: 199\n",
      "french_vocab_size: 344\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 3.4749 - accuracy: 0.4167 - val_loss: nan - val_accuracy: 0.4606\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 2.4429 - accuracy: 0.4684 - val_loss: nan - val_accuracy: 0.4792\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 2.2106 - accuracy: 0.5176 - val_loss: nan - val_accuracy: 0.5428\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 1.9780 - accuracy: 0.5566 - val_loss: nan - val_accuracy: 0.5656\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 1.8046 - accuracy: 0.5713 - val_loss: nan - val_accuracy: 0.5778\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 1.7033 - accuracy: 0.5801 - val_loss: nan - val_accuracy: 0.5873\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 1.6331 - accuracy: 0.5886 - val_loss: nan - val_accuracy: 0.5893\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 1.5757 - accuracy: 0.5953 - val_loss: nan - val_accuracy: 0.6003\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 1.5258 - accuracy: 0.6058 - val_loss: nan - val_accuracy: 0.6086\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 1.4803 - accuracy: 0.6131 - val_loss: nan - val_accuracy: 0.6167\n",
      "new jersey est parfois parfois en en mais il est est en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "def simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a basic RNN on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Build the layers\n",
    "    print(\"input_shape: {}\".format(input_shape))\n",
    "    print(\"output_sequence_length: {}\".format(output_sequence_length))\n",
    "    print(\"english_vocab_size: {}\".format(english_vocab_size))\n",
    "    print(\"french_vocab_size: {}\".format(french_vocab_size))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    input_seq = Input(input_shape[1:])\n",
    "    rnn = GRU(64, return_sequences=True)(input_seq)\n",
    "    logits = TimeDistributed(Dense(french_vocab_size))(rnn)\n",
    "\n",
    "    model = Model(input_seq, Activation('softmax')(logits))\n",
    "    \n",
    "    learning_rate = 1e-3 \n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tests.test_simple_model(simple_model)\n",
    "\n",
    "# Reshaping the input to work with a basic RNN\n",
    "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))\n",
    "\n",
    "# Train the neural network\n",
    "simple_rnn_model = simple_model(\n",
    "    tmp_x.shape,\n",
    "    max_french_sequence_length,\n",
    "    english_vocab_size,\n",
    "    french_vocab_size)\n",
    "simple_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n",
    "\n",
    "\n",
    "# Print prediction(s)\n",
    "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english: new jersey is sometimes quiet during autumn and it is snowy in april         \n",
      "french:  new jersey est parfois parfois en en mais il est est en en        \n",
      "\n",
      "\n",
      "english: the united states is usually chilly during july and it is usually freezing in november       \n",
      "french:  la états unis est jamais chaud en en mais il est est agréable en en      \n",
      "\n",
      "\n",
      "english: california is usually quiet during march and it is usually hot in june         \n",
      "french:  new est est jamais en en et il est est est en en        \n",
      "\n",
      "\n",
      "english: the united states is sometimes mild during june and it is cold in september        \n",
      "french:  la états unis est parfois parfois en en mais il est est en en       \n",
      "\n",
      "\n",
      "english: your least liked fruit is the grape but my least liked is the apple        \n",
      "french:  elle fruit le moins aimé la la mais son moins aimé aimé la la       \n",
      "\n",
      "\n",
      "english: his favorite fruit is the orange but my favorite is the grape          \n",
      "french:  elle fruit préféré est la la mais son préféré est la la         \n",
      "\n",
      "\n",
      "english: paris is relaxing during december but it is usually chilly in july          \n",
      "french:  new est est en en et il est est est en en         \n",
      "\n",
      "\n",
      "english: new jersey is busy during spring and it is never hot in march         \n",
      "french:  new jersey est est en l' et il est est jamais en en        \n",
      "\n",
      "\n",
      "english: our least liked fruit is the lemon but my least liked is the grape        \n",
      "french:  elle fruit le moins aimé la la mais son moins plus aimé la la       \n",
      "\n",
      "\n",
      "english: the united states is sometimes busy during january and it is sometimes warm in november       \n",
      "french:  la états unis est parfois parfois en en mais il est est parfois en en      \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print prediction(s)\n",
    "for i in range(10):\n",
    "    print(\"english:\", tokens_to_text(tmp_x[i:i+1], english_tokenizer).replace('<PAD>', ''))\n",
    "    prediction = simple_rnn_model.predict(tmp_x[i:i+1])\n",
    "    print(\"french: \", logits_to_text(prediction[0], french_tokenizer).replace('<PAD>', ''))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Embedding (IMPLEMENTATION)\n",
    "![RNN](images/embedding.png)\n",
    "You've turned the words into ids, but there's a better representation of a word.  This is called word embeddings.  An embedding is a vector representation of the word that is close to similar words in n-dimensional space, where the n represents the size of the embedding vectors.\n",
    "\n",
    "In this model, you'll create a RNN model using embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: (137861, 21)\n",
      "output_sequence_length: 21\n",
      "english_vocab_size: 199\n",
      "french_vocab_size: 344\n",
      "input_seq.shape: (None, 21)\n",
      "embedding.shape: (None, 21, 64)\n",
      "\n",
      "\n",
      "input_shape: (137861, 21)\n",
      "output_sequence_length: 21\n",
      "english_vocab_size: 199\n",
      "french_vocab_size: 344\n",
      "input_seq.shape: (None, 21)\n",
      "embedding.shape: (None, 21, 64)\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 3.7481 - accuracy: 0.4011 - val_loss: nan - val_accuracy: 0.4093\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 2.6350 - accuracy: 0.4574 - val_loss: nan - val_accuracy: 0.5206\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 1.9185 - accuracy: 0.5683 - val_loss: nan - val_accuracy: 0.6172\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 1.4235 - accuracy: 0.6547 - val_loss: nan - val_accuracy: 0.6950\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 1.1110 - accuracy: 0.7274 - val_loss: nan - val_accuracy: 0.7532\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.9201 - accuracy: 0.7667 - val_loss: nan - val_accuracy: 0.7810\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.7941 - accuracy: 0.7900 - val_loss: nan - val_accuracy: 0.8003\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.7055 - accuracy: 0.8085 - val_loss: nan - val_accuracy: 0.8168\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.6378 - accuracy: 0.8232 - val_loss: nan - val_accuracy: 0.8296\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.5854 - accuracy: 0.8342 - val_loss: nan - val_accuracy: 0.8390\n",
      "new jersey est parfois calme en l' et il il neigeux neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "def embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a RNN model using word embedding on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    print(\"input_shape: {}\".format(input_shape))\n",
    "    print(\"output_sequence_length: {}\".format(output_sequence_length))\n",
    "    print(\"english_vocab_size: {}\".format(english_vocab_size))\n",
    "    print(\"french_vocab_size: {}\".format(french_vocab_size))\n",
    "\n",
    "    input_seq = Input(input_shape[1:])\n",
    "    print(\"input_seq.shape: {}\".format(input_seq.shape))\n",
    "    embedding = Embedding(english_vocab_size+1, 64, input_length=input_shape[1])(input_seq)\n",
    "    print(\"embedding.shape: {}\".format(embedding.shape))\n",
    "    print(\"\\n\")\n",
    "    rnn = GRU(64, return_sequences=True)(embedding)\n",
    "    logits = TimeDistributed(Dense(french_vocab_size))(rnn)\n",
    "\n",
    "    model = Model(input_seq, Activation('softmax')(logits))\n",
    "    \n",
    "    learning_rate = 1e-3 \n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tests.test_embed_model(embed_model)\n",
    "\n",
    "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
    "\n",
    "# TODO: Train the neural network\n",
    "simple_embed_model = embed_model(\n",
    "    tmp_x.shape,\n",
    "    max_french_sequence_length,\n",
    "    english_vocab_size,\n",
    "    french_vocab_size)\n",
    "simple_embed_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Print prediction(s)\n",
    "print(logits_to_text(simple_embed_model.predict(tmp_x[:1])[0], french_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english:  new jersey is sometimes quiet during autumn and it is snowy in april         \n",
      "french:   new jersey est parfois calme en l' et il il neigeux neigeux en avril       \n",
      "\n",
      "\n",
      "english:  the united states is usually chilly during july and it is usually freezing in november       \n",
      "french:   les états unis est généralement froid en juillet et il est généralement en en novembre      \n",
      "\n",
      "\n",
      "english:  california is usually quiet during march and it is usually hot in june         \n",
      "french:   californie est généralement calme en mars et il est est chaud chaud juin        \n",
      "\n",
      "\n",
      "english:  the united states is sometimes mild during june and it is cold in september        \n",
      "french:   les états unis est parfois doux en juin et il est froid en septembre       \n",
      "\n",
      "\n",
      "english:  your least liked fruit is the grape but my least liked is the apple        \n",
      "french:   votre fruit moins moins aimé la raisin mais mon moins aimé est la pomme       \n",
      "\n",
      "\n",
      "english:  his favorite fruit is the orange but my favorite is the grape          \n",
      "french:   son fruit préféré est la mais mais préféré             \n",
      "\n",
      "\n",
      "english:  paris is relaxing during december but it is usually chilly in july          \n",
      "french:   paris est relaxant au décembre mais il est généralement froid en juillet         \n",
      "\n",
      "\n",
      "english:  new jersey is busy during spring and it is never hot in march         \n",
      "french:   new jersey est occupé en printemps et il est jamais chaud en mars        \n",
      "\n",
      "\n",
      "english:  our least liked fruit is the lemon but my least liked is the grape        \n",
      "french:   notre fruit moins moins aimé la citron mais mon moins aimé est la raisin       \n",
      "\n",
      "\n",
      "english:  the united states is sometimes busy during january and it is sometimes warm in november       \n",
      "french:   les états unis est parfois occupé en janvier et il est parfois chaud en novembre      \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print prediction(s)\n",
    "for i in range(10):\n",
    "    print(\"english: \", tokens_to_text(tmp_x[i:i+1], english_tokenizer).replace('<PAD>', ''))\n",
    "    prediction = simple_embed_model.predict(tmp_x[i:i+1])\n",
    "    print(\"french:  \", logits_to_text(prediction[0], french_tokenizer).replace('<PAD>', ''))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Bidirectional RNNs (IMPLEMENTATION)\n",
    "![RNN](images/bidirectional.png)\n",
    "One restriction of a RNN is that it can't see the future input, only the past.  This is where bidirectional recurrent neural networks come in.  They are able to see the future data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: (137861, 21, 1)\n",
      "output_sequence_length: 21\n",
      "english_vocab_size: 199\n",
      "french_vocab_size: 344\n",
      "input_seq.shape: (None, 21, 1)\n",
      "embedding.shape: (None, 21, 64)\n",
      "\n",
      "\n",
      "Model: \"functional_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        [(None, 21, 1)]           0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Squeeze_4 (Tenso [(None, 21)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_19 (Embedding)     (None, 21, 64)            12800     \n",
      "_________________________________________________________________\n",
      "bidirectional_15 (Bidirectio (None, 21, 128)           49920     \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 21, 344)           44376     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 21, 344)           0         \n",
      "=================================================================\n",
      "Total params: 107,096\n",
      "Trainable params: 107,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "******tmp_x.shape: (137861, 21, 1)\n",
      "input_shape: (137861, 21, 1)\n",
      "output_sequence_length: 21\n",
      "english_vocab_size: 199\n",
      "french_vocab_size: 344\n",
      "input_seq.shape: (None, 21, 1)\n",
      "embedding.shape: (None, 21, 64)\n",
      "\n",
      "\n",
      "Model: \"functional_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        [(None, 21, 1)]           0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Squeeze_5 (Tenso [(None, 21)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_20 (Embedding)     (None, 21, 64)            12800     \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 21, 128)           49920     \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 21, 344)           44376     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 21, 344)           0         \n",
      "=================================================================\n",
      "Total params: 107,096\n",
      "Trainable params: 107,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 3s 23ms/step - loss: 3.4228 - accuracy: 0.4299 - val_loss: nan - val_accuracy: 0.4756\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 2s 19ms/step - loss: 2.2194 - accuracy: 0.5194 - val_loss: nan - val_accuracy: 0.5944\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 1.4768 - accuracy: 0.6357 - val_loss: nan - val_accuracy: 0.6781\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 1.1291 - accuracy: 0.7051 - val_loss: nan - val_accuracy: 0.7317\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.9126 - accuracy: 0.7496 - val_loss: nan - val_accuracy: 0.7693\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.7612 - accuracy: 0.7846 - val_loss: nan - val_accuracy: 0.8012\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.6475 - accuracy: 0.8136 - val_loss: nan - val_accuracy: 0.8267\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.5646 - accuracy: 0.8341 - val_loss: nan - val_accuracy: 0.8425\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.5021 - accuracy: 0.8504 - val_loss: nan - val_accuracy: 0.8582\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 2s 19ms/step - loss: 0.4536 - accuracy: 0.8640 - val_loss: nan - val_accuracy: 0.8710\n",
      "new jersey est parfois calme en automne et il il neigeux en en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a bidirectional RNN model on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    print(\"input_shape: {}\".format(input_shape))\n",
    "    print(\"output_sequence_length: {}\".format(output_sequence_length))\n",
    "    print(\"english_vocab_size: {}\".format(english_vocab_size))\n",
    "    print(\"french_vocab_size: {}\".format(french_vocab_size))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    input_seq = Input(input_shape[1:])\n",
    "    \n",
    "    input_seq_squeezed = keras.backend.squeeze(input_seq, 2)\n",
    "    embedding = Embedding(english_vocab_size+1, 64, input_length=input_shape[1])(input_seq_squeezed)\n",
    "    rnn = Bidirectional(GRU(64, return_sequences=True))(embedding)\n",
    "    logits = TimeDistributed(Dense(french_vocab_size))(rnn)\n",
    "\n",
    "    model = Model(input_seq, Activation('softmax')(logits))\n",
    "    \n",
    "    learning_rate = 1e-3 \n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "tests.test_bd_model(bd_model)\n",
    "\n",
    "# TODO: Train and Print prediction(s)\n",
    "# Reshape the input\n",
    "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))\n",
    "\n",
    "# Train the neural network\n",
    "simple_bd_model = bd_model(\n",
    "    tmp_x.shape,\n",
    "    max_french_sequence_length,\n",
    "    english_vocab_size,\n",
    "    french_vocab_size)\n",
    "simple_bd_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Print prediction(s)\n",
    "print(logits_to_text(simple_bd_model.predict(tmp_x[:1])[0], french_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new jersey is sometimes quiet during autumn and it is snowy in april         \n",
      "new jersey est parfois calme en automne et il il neigeux en en avril       \n",
      "\n",
      "\n",
      "the united states is usually chilly during july and it is usually freezing in november       \n",
      "les états unis est généralement froid en juillet et il est habituellement en en novembre      \n",
      "\n",
      "\n",
      "california is usually quiet during march and it is usually hot in june         \n",
      "californie est généralement calme en mars et il est généralement chaud en juin        \n",
      "\n",
      "\n",
      "the united states is sometimes mild during june and it is cold in september        \n",
      "les états unis est parfois doux en juin et il est froid en septembre       \n",
      "\n",
      "\n",
      "your least liked fruit is the grape but my least liked is the apple        \n",
      "votre fruit moins moins est le raisin mais mon moins aimé est la pomme       \n",
      "\n",
      "\n",
      "his favorite fruit is the orange but my favorite is the grape          \n",
      "son fruit préféré est l'orange mais mais préféré préféré est           \n",
      "\n",
      "\n",
      "paris is relaxing during december but it is usually chilly in july          \n",
      "paris est relaxant en décembre mais il est généralement froid en juillet         \n",
      "\n",
      "\n",
      "new jersey is busy during spring and it is never hot in march         \n",
      "new jersey est occupé au printemps et il est jamais chaud en mars        \n",
      "\n",
      "\n",
      "our least liked fruit is the lemon but my least liked is the grape        \n",
      "notre moins aimé moins est le citron mais mon moins aimé est le raisin       \n",
      "\n",
      "\n",
      "the united states is sometimes busy during january and it is sometimes warm in november       \n",
      "les états unis est parfois occupé en janvier et il est parfois chaud en novembre      \n",
      "\n",
      "\n",
      "the lime is her least liked fruit but the banana is my least liked        \n",
      "la chaux est son moins moins des fruits mais la banane mon moins aimé aimé      \n",
      "\n",
      "\n",
      "he saw a old yellow truck                \n",
      "il a vu un camion camion jaune              \n",
      "\n",
      "\n",
      "india is rainy during june and it is sometimes warm in november          \n",
      "l' inde pluvieux en en et il est parfois chaud en novembre novembre        \n",
      "\n",
      "\n",
      "that cat was my most loved animal               \n",
      "ce chat était mon animal le plus aimé             \n",
      "\n",
      "\n",
      "he dislikes grapefruit limes and lemons                \n",
      "il aime pas pamplemousse citrons citrons et citrons citrons            \n",
      "\n",
      "\n",
      "her least liked fruit is the lemon but his least liked is the grapefruit        \n",
      "son fruit est moins aimé le citron mais son moins aimé est le pamplemousse       \n",
      "\n",
      "\n",
      "california is never cold during february but it is sometimes freezing in june         \n",
      "california ne fait froid froid en février mais mais il parfois le en juin juin      \n",
      "\n",
      "\n",
      "china is usually pleasant during autumn and it is usually quiet in october         \n",
      "chine est généralement agréable en l' et il est est généralement calme en octobre       \n",
      "\n",
      "\n",
      "paris is never freezing during november but it is wonderful in october          \n",
      "paris est jamais le gel gel mais mais il il est merveilleux en octobre       \n",
      "\n",
      "\n",
      "the united states is never rainy during january but it is sometimes mild in october       \n",
      "les états unis est jamais pluvieux en janvier mais il est parfois doux en octobre      \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(tokens_to_text(tmp_x[i:i+1], english_tokenizer).replace('<PAD>', ''))\n",
    "    prediction = simple_bd_model.predict(tmp_x[i:i+1])\n",
    "    print(logits_to_text(prediction[0], french_tokenizer).replace('<PAD>', ''))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Encoder-Decoder (OPTIONAL)\n",
    "Time to look at encoder-decoder models.  This model is made up of an encoder and decoder. The encoder creates a matrix representation of the sentence.  The decoder takes this matrix as input and predicts the translation as output.\n",
    "\n",
    "Create an encoder-decoder model in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: (137861, 15, 1)\n",
      "output_sequence_length: 21\n",
      "english_vocab_size: 199\n",
      "french_vocab_size: 344\n",
      "\n",
      "\n",
      "input_shape: (137861, 21, 1)\n",
      "output_sequence_length: 21\n",
      "english_vocab_size: 199\n",
      "french_vocab_size: 344\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "862/862 [==============================] - 7s 9ms/step - loss: 1.8117 - accuracy: 0.5567 - val_loss: nan - val_accuracy: 0.6156\n",
      "Epoch 2/10\n",
      "862/862 [==============================] - 7s 8ms/step - loss: 1.2903 - accuracy: 0.6313 - val_loss: nan - val_accuracy: 0.6509\n",
      "Epoch 3/10\n",
      "862/862 [==============================] - 7s 8ms/step - loss: 1.1801 - accuracy: 0.6583 - val_loss: nan - val_accuracy: 0.6632\n",
      "Epoch 4/10\n",
      "862/862 [==============================] - 7s 8ms/step - loss: 1.1447 - accuracy: 0.6675 - val_loss: nan - val_accuracy: 0.6728\n",
      "Epoch 5/10\n",
      "862/862 [==============================] - 7s 8ms/step - loss: 1.0818 - accuracy: 0.6786 - val_loss: nan - val_accuracy: 0.6912\n",
      "Epoch 6/10\n",
      "862/862 [==============================] - 7s 8ms/step - loss: 0.9845 - accuracy: 0.6958 - val_loss: nan - val_accuracy: 0.7080\n",
      "Epoch 7/10\n",
      "862/862 [==============================] - 7s 8ms/step - loss: 0.9118 - accuracy: 0.7112 - val_loss: nan - val_accuracy: 0.7193\n",
      "Epoch 8/10\n",
      "862/862 [==============================] - 7s 8ms/step - loss: 0.8356 - accuracy: 0.7264 - val_loss: nan - val_accuracy: 0.7272\n",
      "Epoch 9/10\n",
      "862/862 [==============================] - 7s 8ms/step - loss: 0.7750 - accuracy: 0.7375 - val_loss: nan - val_accuracy: 0.7353\n",
      "Epoch 10/10\n",
      "862/862 [==============================] - 8s 9ms/step - loss: 0.7385 - accuracy: 0.7461 - val_loss: nan - val_accuracy: 0.7585\n",
      "new jersey est parfois calme au mois de il il il en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def encdec_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train an encoder-decoder model on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # OPTIONAL: Implement\n",
    "    print(\"input_shape: {}\".format(input_shape))\n",
    "    print(\"output_sequence_length: {}\".format(output_sequence_length))\n",
    "    print(\"english_vocab_size: {}\".format(english_vocab_size))\n",
    "    print(\"french_vocab_size: {}\".format(french_vocab_size))\n",
    "    print(\"\\n\")\n",
    "    gru_units = 256\n",
    "    fc_units  = 256\n",
    "    \n",
    "    input_seq = Input(input_shape[1:])\n",
    "    \n",
    "    encoder_rnn = GRU(gru_units, return_sequences=False)(input_seq)\n",
    "    #print(\"encoder_rnn.shape: {}\".format(encoder_rnn.shape))\n",
    "    \n",
    "    repeat_vector = RepeatVector(output_sequence_length)(encoder_rnn)\n",
    "    #print(\"repeat_vector.shape: {}\".format(repeat_vector.shape))\n",
    "    \n",
    "    decoder_rnn = GRU(gru_units, return_sequences=True)(repeat_vector)\n",
    "    #print(\"decoder_rnn.shape: {}\".format(decoder_rnn.shape))\n",
    "    \n",
    "    fc_layer = Dense(fc_units, activation='relu')(decoder_rnn)\n",
    "    \n",
    "    logits = TimeDistributed(Dense(french_vocab_size))(fc_layer)\n",
    "\n",
    "    model = Model(input_seq, Activation('softmax')(logits))\n",
    "    \n",
    "    learning_rate = 1e-3 \n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tests.test_encdec_model(encdec_model)\n",
    "\n",
    "# OPTIONAL: Train and Print prediction(s)\n",
    "# Reshape the input\n",
    "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))\n",
    "\n",
    "# Train the neural network\n",
    "simple_encdec_model = encdec_model(\n",
    "    tmp_x.shape,\n",
    "    max_french_sequence_length,\n",
    "    english_vocab_size,\n",
    "    french_vocab_size)\n",
    "simple_encdec_model.fit(tmp_x, preproc_french_sentences, batch_size=128, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Print prediction(s)\n",
    "print(logits_to_text(simple_encdec_model.predict(tmp_x[:1])[0], french_tokenizer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Custom (IMPLEMENTATION)\n",
    "Use everything you learned from the previous models to create a model that incorporates embedding and a bidirectional rnn into one model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: (137861, 15)\n",
      "output_sequence_length: 21\n",
      "english_vocab_size: 199\n",
      "french_vocab_size: 344\n",
      "\n",
      "\n",
      "input_seq.shape: (None, 15)\n",
      "embedding.shape: (None, 15, 256)\n",
      "Final Model Loaded\n",
      "input_shape: (137861, 21)\n",
      "output_sequence_length: 21\n",
      "english_vocab_size: 199\n",
      "french_vocab_size: 344\n",
      "\n",
      "\n",
      "input_seq.shape: (None, 21)\n",
      "embedding.shape: (None, 21, 256)\n",
      "Epoch 1/10\n",
      "862/862 [==============================] - 15s 17ms/step - loss: 1.3114 - accuracy: 0.6660 - val_loss: nan - val_accuracy: 0.7635\n",
      "Epoch 2/10\n",
      "862/862 [==============================] - 14s 16ms/step - loss: 0.5805 - accuracy: 0.8281 - val_loss: nan - val_accuracy: 0.8765\n",
      "Epoch 3/10\n",
      "862/862 [==============================] - 14s 16ms/step - loss: 0.2744 - accuracy: 0.9203 - val_loss: nan - val_accuracy: 0.9361\n",
      "Epoch 4/10\n",
      "862/862 [==============================] - 14s 16ms/step - loss: 0.1654 - accuracy: 0.9504 - val_loss: nan - val_accuracy: 0.9564\n",
      "Epoch 5/10\n",
      "862/862 [==============================] - 14s 16ms/step - loss: 0.1231 - accuracy: 0.9622 - val_loss: nan - val_accuracy: 0.9628\n",
      "Epoch 6/10\n",
      "862/862 [==============================] - 14s 16ms/step - loss: 0.0965 - accuracy: 0.9702 - val_loss: nan - val_accuracy: 0.9704\n",
      "Epoch 7/10\n",
      "862/862 [==============================] - 14s 16ms/step - loss: 0.0875 - accuracy: 0.9730 - val_loss: nan - val_accuracy: 0.9712\n",
      "Epoch 8/10\n",
      "862/862 [==============================] - 14s 16ms/step - loss: 0.0702 - accuracy: 0.9780 - val_loss: nan - val_accuracy: 0.9729\n",
      "Epoch 9/10\n",
      "862/862 [==============================] - 14s 16ms/step - loss: 0.0631 - accuracy: 0.9804 - val_loss: nan - val_accuracy: 0.9774\n",
      "Epoch 10/10\n",
      "862/862 [==============================] - 14s 17ms/step - loss: 0.0577 - accuracy: 0.9819 - val_loss: nan - val_accuracy: 0.9725\n",
      "new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "def model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a model that incorporates embedding, encoder-decoder, and bidirectional RNN on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    print(\"input_shape: {}\".format(input_shape))\n",
    "    print(\"output_sequence_length: {}\".format(output_sequence_length))\n",
    "    print(\"english_vocab_size: {}\".format(english_vocab_size))\n",
    "    print(\"french_vocab_size: {}\".format(french_vocab_size))\n",
    "    print(\"\\n\")\n",
    "    learning_rate = 1e-3 \n",
    "    embedding_size = 256\n",
    "    gru_units = 256\n",
    "    fc_units  = 256\n",
    "    \n",
    "    input_seq = Input(input_shape[1:])\n",
    "    \n",
    "    print(\"input_seq.shape: {}\".format(input_seq.shape))\n",
    "    embedding = Embedding(english_vocab_size+1, embedding_size, input_length=input_shape[1])(input_seq)\n",
    "    print(\"embedding.shape: {}\".format(embedding.shape))\n",
    "    \n",
    "    #encoder_rnn = GRU(gru_units, return_sequences=False)(embedding)\n",
    "    #print(\"encoder_rnn.shape: {}\".format(encoder_rnn.shape))\n",
    "    \n",
    "    forward_encoder_layer  = GRU(gru_units, return_sequences=False)\n",
    "    backward_encoder_layer = GRU(gru_units, return_sequences=False, go_backwards=True)\n",
    "    encoder_rnn = Bidirectional(forward_encoder_layer, backward_layer=backward_encoder_layer)(embedding)\n",
    "    \n",
    "    repeat_vector = RepeatVector(output_sequence_length)(encoder_rnn)\n",
    "    #print(\"repeat_vector.shape: {}\".format(repeat_vector.shape))\n",
    "    \n",
    "    #decoder_rnn = GRU(gru_units, return_sequences=True)(repeat_vector)\n",
    "    \n",
    "    forward_decoder_layer  = GRU(gru_units, return_sequences=True)\n",
    "    backward_decoder_layer = GRU(gru_units, return_sequences=True, go_backwards=True)\n",
    "    decoder_rnn = Bidirectional(forward_decoder_layer, backward_layer=backward_decoder_layer)(repeat_vector)\n",
    "    \n",
    "    #print(\"decoder_rnn.shape: {}\".format(decoder_rnn.shape))\n",
    "    \n",
    "    fc_layer = Dense(fc_units, activation='relu')(decoder_rnn)\n",
    "    \n",
    "    logits = TimeDistributed(Dense(french_vocab_size))(decoder_rnn)\n",
    "\n",
    "    model = Model(input_seq, Activation('softmax')(logits))\n",
    "    \n",
    "    \n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tests.test_model_final(model_final)\n",
    "\n",
    "\n",
    "print('Final Model Loaded')\n",
    "# Reshape the input\n",
    "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))\n",
    "\n",
    "# Train the neural network\n",
    "model = model_final(\n",
    "    tmp_x.shape,\n",
    "    max_french_sequence_length,\n",
    "    english_vocab_size,\n",
    "    french_vocab_size)\n",
    "model.fit(tmp_x, preproc_french_sentences, batch_size=128, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Print prediction(s)\n",
    "print(logits_to_text(model.predict(tmp_x[:1])[0], french_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english:  new jersey is sometimes quiet during autumn and it is snowy in april         \n",
      "french :  new jersey est parfois calme pendant l' automne et il est neigeux en avril       \n",
      "\n",
      "\n",
      "english:  the united states is usually chilly during july and it is usually freezing in november       \n",
      "french :  les états unis est généralement froid en juillet et il gèle habituellement en novembre       \n",
      "\n",
      "\n",
      "english:  california is usually quiet during march and it is usually hot in june         \n",
      "french :  california est généralement calme en mars et il est généralement chaud en juin        \n",
      "\n",
      "\n",
      "english:  the united states is sometimes mild during june and it is cold in september        \n",
      "french :  les états unis est parfois légère en juin et il fait froid en septembre       \n",
      "\n",
      "\n",
      "english:  your least liked fruit is the grape but my least liked is the apple        \n",
      "french :  votre fruit aimé fruit est le raisin mais mon moins aimé est la pomme       \n",
      "\n",
      "\n",
      "english:  his favorite fruit is the orange but my favorite is the grape          \n",
      "french :  son fruit préféré est l'orange mais mon est le le           \n",
      "\n",
      "\n",
      "english:  paris is relaxing during december but it is usually chilly in july          \n",
      "french :  paris est relaxant en décembre mais il est généralement froid en juillet         \n",
      "\n",
      "\n",
      "english:  new jersey is busy during spring and it is never hot in march         \n",
      "french :  new jersey est occupé au printemps et il est jamais chaude en mars        \n",
      "\n",
      "\n",
      "english:  our least liked fruit is the lemon but my least liked is the grape        \n",
      "french :  notre fruit est moins aimé le citron mais mon moins aimé est le raisin       \n",
      "\n",
      "\n",
      "english:  the united states is sometimes busy during january and it is sometimes warm in november       \n",
      "french :  les états unis est parfois occupé en janvier et il est parfois chaud en novembre      \n",
      "\n",
      "\n",
      "english:  the lime is her least liked fruit but the banana is my least liked        \n",
      "french :  la chaux est son moins aimé des fruits mais la banane est mon moins aimé      \n",
      "\n",
      "\n",
      "english:  he saw a old yellow truck                \n",
      "french :  il a vu un vieux camion jaune              \n",
      "\n",
      "\n",
      "english:  india is rainy during june and it is sometimes warm in november          \n",
      "french :  inde est pluvieux en juin et il est parfois chaud en novembre         \n",
      "\n",
      "\n",
      "english:  that cat was my most loved animal               \n",
      "french :  ce chat était mon animal le plus aimé             \n",
      "\n",
      "\n",
      "english:  he dislikes grapefruit limes and lemons                \n",
      "french :  il n'aime pamplemousse pamplemousse citrons verts et verts             \n",
      "\n",
      "\n",
      "english:  her least liked fruit is the lemon but his least liked is the grapefruit        \n",
      "french :  son fruit est moins aimé le citron mais son moins aimé est le pamplemousse       \n",
      "\n",
      "\n",
      "english:  california is never cold during february but it is sometimes freezing in june         \n",
      "french :  californie ne fait jamais froid en février mais il est parfois le gel en juin      \n",
      "\n",
      "\n",
      "english:  china is usually pleasant during autumn and it is usually quiet in october         \n",
      "french :  chine est généralement agréable en automne et il est généralement calme en octobre        \n",
      "\n",
      "\n",
      "english:  paris is never freezing during november but it is wonderful in october          \n",
      "french :  paris est jamais le gel en septembre mais il est merveilleux en octobre        \n",
      "\n",
      "\n",
      "english:  the united states is never rainy during january but it is sometimes mild in october       \n",
      "french :  les états unis est jamais pluvieux en janvier mais il est parfois doux en octobre      \n",
      "\n",
      "\n",
      "english:  china is usually pleasant during november and it is never quiet in october         \n",
      "french :  chine est généralement agréable en novembre et il est jamais tranquille en octobre        \n",
      "\n",
      "\n",
      "english:  the united states is never nice during february but it is sometimes pleasant in april       \n",
      "french :  les états unis est jamais agréable en février mais il est parfois agréable en avril      \n",
      "\n",
      "\n",
      "english:  india is never busy during autumn and it is mild in spring          \n",
      "french :  l' inde est jamais occupé à l'automne et il est doux au printemps        \n",
      "\n",
      "\n",
      "english:  paris is mild during summer but it is usually busy in april          \n",
      "french :  paris est doux pendant l' été mais il est généralement occupé en avril        \n",
      "\n",
      "\n",
      "english:  france is never cold during september and it is snowy in october          \n",
      "french :  france ne fait jamais froid en septembre et il est neigeux en octobre        \n",
      "\n",
      "\n",
      "english:  california is never cold during may and it is sometimes chilly in march         \n",
      "french :  californie ne fait jamais froid au mois de mai et il est parfois frisquet frisquet mars     \n",
      "\n",
      "\n",
      "english:  he dislikes lemons grapes and mangoes                \n",
      "french :  il déteste les citrons les raisins et les mangues            \n",
      "\n",
      "\n",
      "english:  their favorite fruit is the mango but our favorite is the pear          \n",
      "french :  leur fruit préféré est la mangue mais notre préféré est la poire         \n",
      "\n",
      "\n",
      "english:  france is sometimes quiet during may and it is never chilly in august         \n",
      "french :  la france est parfois calme au mois de mai et il est jamais froid en août     \n",
      "\n",
      "\n",
      "english:  paris is never pleasant during september and it is beautiful in autumn          \n",
      "french :  paris est jamais agréable en septembre et il est beau à l' automne        \n",
      "\n",
      "\n",
      "english:  he dislikes apples peaches and grapes                \n",
      "french :  il aime pas les pommes les pêches et les raisins           \n",
      "\n",
      "\n",
      "english:  california is usually freezing during december and it is busy in april          \n",
      "french :  la californie est le gel habituellement en décembre et il est occupé en avril       \n",
      "\n",
      "\n",
      "english:  your most feared animal is that shark               \n",
      "french :  votre animal le plus redouté est que le requin            \n",
      "\n",
      "\n",
      "english:  paris is usually wet during august and it is never dry in november         \n",
      "french :  paris est généralement humide au mois d' août et il est jamais sec en novembre      \n",
      "\n",
      "\n",
      "english:  paris is usually beautiful during september and it is usually snowy in november         \n",
      "french :  paris est généralement beau en septembre et il est généralement enneigée en enneigée        \n",
      "\n",
      "\n",
      "english:  the united states is never wet during january but it is usually hot in october       \n",
      "french :  les états unis est jamais humide en janvier mais il est généralement chaud en octobre      \n",
      "\n",
      "\n",
      "english:  we like oranges mangoes and grapes                \n",
      "french :  nous aimons les oranges les mangues et les raisins            \n",
      "\n",
      "\n",
      "english:  they like pears apples and mangoes                \n",
      "french :  ils aiment les poires les pommes et les mangues            \n",
      "\n",
      "\n",
      "english:  she dislikes that little red truck                \n",
      "french :  elle déteste ce petit camion rouge               \n",
      "\n",
      "\n",
      "english:  the grapefruit is my most loved fruit but the banana is her most loved        \n",
      "french :  le pamplemousse est mon fruit le plus cher mais la banane est la plus aimée      \n",
      "\n",
      "\n",
      "english:  france is snowy during may and it is never busy in autumn          \n",
      "french :  la france est la neige au mois de mai et il est jamais trop à l' automne    \n",
      "\n",
      "\n",
      "english:  china is usually mild during winter but it is never busy in february         \n",
      "french :  chine est généralement doux pendant l' hiver mais il est jamais occupé en février       \n",
      "\n",
      "\n",
      "english:  china is never nice during july but it is usually snowy in spring         \n",
      "french :  chine est jamais agréable en juillet mais il est généralement enneigée au printemps        \n",
      "\n",
      "\n",
      "english:  california is busy during november but it is rainy in autumn           \n",
      "french :  californie est occupé au mois de novembre mais il pleut l' à l' automne       \n",
      "\n",
      "\n",
      "english:  china is warm during spring and it is sometimes cold in february          \n",
      "french :  chine est chaud au printemps et il est parfois froid en février         \n",
      "\n",
      "\n",
      "english:  california is usually beautiful during winter but it is never busy in february         \n",
      "french :  californie est généralement beau pendant l' hiver mais il est jamais occupé en février       \n",
      "\n",
      "\n",
      "english:  france is wonderful during november but it is sometimes hot in september          \n",
      "french :  france est merveilleux au mois de novembre mais il est parfois chaud en septembre       \n",
      "\n",
      "\n",
      "english:  india is usually pleasant during november but it is never relaxing in july         \n",
      "french :  l' inde est généralement agréable en novembre mais il est jamais relaxant en juillet       \n",
      "\n",
      "\n",
      "english:  the united states is never freezing during autumn but it is never busy in june       \n",
      "french :  les états unis ne sont jamais gel pendant l' automne mais il est jamais occupé en juin    \n",
      "\n",
      "\n",
      "english:  paris is sometimes warm during june but it is usually hot in july         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "french :  paris est parfois chaud en juin mais il est généralement chaud en juillet        \n",
      "\n",
      "\n",
      "english:  paris is never hot during summer and it is usually mild in winter         \n",
      "french :  paris est jamais chaude pendant l' été et il est généralement doux en hiver       \n",
      "\n",
      "\n",
      "english:  she disliked a rusty yellow car                \n",
      "french :  elle n'aimait pas une voiture jaune rouillée              \n",
      "\n",
      "\n",
      "english:  france is usually quiet during november but it is sometimes warm in february         \n",
      "french :  la france est généralement calme en novembre mais il est parfois chaud en février       \n",
      "\n",
      "\n",
      "english:  new jersey is never wet during november and it is mild in august         \n",
      "french :  new jersey est jamais humide au mois de novembre et il est doux au mois d' août    \n",
      "\n",
      "\n",
      "english:  we like peaches pears and strawberries                \n",
      "french :  nous aimons les pêches les poires et les fraises            \n",
      "\n",
      "\n",
      "english:  the orange is her least liked fruit but the grapefruit is their least liked        \n",
      "french :  l'orange est la moins aimé des fruits mais le pamplemousse est leur moins aimé       \n",
      "\n",
      "\n",
      "english:  china is never rainy during november and it is quiet in january          \n",
      "french :  chine est jamais pluvieux en novembre et il est calme en janvier         \n",
      "\n",
      "\n",
      "english:  china is relaxing during march but it is sometimes snowy in september          \n",
      "french :  chine est relaxant au mois de mars mais il est parfois enneigée en septembre       \n",
      "\n",
      "\n",
      "english:  paris is wonderful during march but it is usually pleasant in june          \n",
      "french :  paris est merveilleux au mois de mars mais il est généralement agréable en juin       \n",
      "\n",
      "\n",
      "english:  new jersey is chilly during autumn and it is sometimes pleasant in spring         \n",
      "french :  new jersey est froid au cours de l' automne et il est parfois agréable au printemps     \n",
      "\n",
      "\n",
      "english:  california is never freezing during october but it is usually quiet in june         \n",
      "french :  la californie est jamais le gel en octobre mais il est généralement calme en juin      \n",
      "\n",
      "\n",
      "english:  new jersey is freezing during winter but it is sometimes wonderful in january         \n",
      "french :  new jersey est le gel pendant l' hiver mais il est parfois merveilleux en janvier      \n",
      "\n",
      "\n",
      "english:  i like grapes pears and strawberries                \n",
      "french :  j'aime les raisins les poires et les fraises             \n",
      "\n",
      "\n",
      "english:  the lemon is my most loved fruit but the strawberry is our most loved        \n",
      "french :  le citron est mon fruit le plus aimé mais la fraise est notre plus aimé      \n",
      "\n",
      "\n",
      "english:  china is usually dry during march but it is nice in november          \n",
      "french :  chine est généralement sec en mars mais il est agréable en novembre         \n",
      "\n",
      "\n",
      "english:  paris is pleasant during december but it is never nice in november          \n",
      "french :  paris est agréable en décembre mais il est jamais agréable en novembre         \n",
      "\n",
      "\n",
      "english:  china is freezing during july but it is relaxing in january           \n",
      "french :  chine gèle en juillet mais il est relaxant en janvier           \n",
      "\n",
      "\n",
      "english:  the apple is our least favorite fruit but the orange is her least favorite        \n",
      "french :  la pomme est notre fruit préféré moins mais l'orange est son moins         \n",
      "\n",
      "\n",
      "english:  he dislikes grapes grapefruit and bananas                \n",
      "french :  il aime pas les raisins le pamplemousse et les bananes           \n",
      "\n",
      "\n",
      "english:  he dislikes apples mangoes and strawberries                \n",
      "french :  il déteste les pommes les mangues et les fraises            \n",
      "\n",
      "\n",
      "english:  china is hot during july but it is never pleasant in january          \n",
      "french :  chine est chaud en juillet mais il est jamais agréable en janvier         \n",
      "\n",
      "\n",
      "english:  india is usually dry during april and it is freezing in february          \n",
      "french :  l' inde est généralement sec en avril et il gèle en février         \n",
      "\n",
      "\n",
      "english:  she is going to the united states next summer             \n",
      "french :  elle va aux états unis l' été prochain             \n",
      "\n",
      "\n",
      "english:  france is sometimes rainy during february and it is usually quiet in spring         \n",
      "french :  la france est parfois pluvieux en février et il est généralement calme au printemps       \n",
      "\n",
      "\n",
      "english:  i plan to visit california next may               \n",
      "french :  je prévois de visiter la en en mai prochain            \n",
      "\n",
      "\n",
      "english:  california is never wet during november and it is sometimes pleasant in september         \n",
      "french :  california est jamais humide en novembre et il est parfois agréable en septembre        \n",
      "\n",
      "\n",
      "english:  they like lemons limes and grapefruit                \n",
      "french :  ils aiment les citrons citrons verts et le pamplemousse            \n",
      "\n",
      "\n",
      "english:  the united states is never beautiful during march and it is usually relaxing in summer       \n",
      "french :  les états unis est jamais belle en mars et il est relaxant habituellement en été      \n",
      "\n",
      "\n",
      "english:  elephants were his most feared animals                \n",
      "french :  les éléphants étaient ses animaux les plus redoutés             \n",
      "\n",
      "\n",
      "english:  the strawberry is their least favorite fruit but the apple is our least favorite        \n",
      "french :  la fraise est leur fruit préféré moins mais la pomme est notre moins préféré       \n",
      "\n",
      "\n",
      "english:  they are going to france next june               \n",
      "french :  ils vont en france en juin prochain              \n",
      "\n",
      "\n",
      "english:  he likes strawberries oranges and limes                \n",
      "french :  il aime les fraises les oranges et les citrons verts           \n",
      "\n",
      "\n",
      "english:  california is never pleasant during winter and it is sometimes wonderful in december         \n",
      "french :  california est jamais agréable pendant l' hiver et il est parfois merveilleux en décembre       \n",
      "\n",
      "\n",
      "english:  the apple is our least favorite fruit but the mango is their least favorite        \n",
      "french :  la pomme est notre fruit préféré moins mais la mangue est leur moins préférée       \n",
      "\n",
      "\n",
      "english:  she likes strawberries oranges and bananas                \n",
      "french :  elle aime les fraises les oranges et les bananes            \n",
      "\n",
      "\n",
      "english:  california is beautiful during january and it is pleasant in february           \n",
      "french :  californie est beau en janvier et il est agréable en février          \n",
      "\n",
      "\n",
      "english:  they dislike grapes mangoes and limes                \n",
      "french :  ils n'aiment pas raisins mangues et citrons citrons verts            \n",
      "\n",
      "\n",
      "english:  she dislikes lemons grapes and oranges                \n",
      "french :  elle déteste les citrons les raisins et les oranges            \n",
      "\n",
      "\n",
      "english:  our least favorite fruit is the banana but your least favorite is the grape        \n",
      "french :  notre fruit préféré moins est la banane mais votre moins préféré est le raisin       \n",
      "\n",
      "\n",
      "english:  california is never cold during december but it is usually warm in may         \n",
      "french :  californie ne fait jamais froid en décembre mais il est habituellement chaud en mai       \n",
      "\n",
      "\n",
      "english:  california is never busy during february and it is usually hot in june         \n",
      "french :  california est jamais occupé en février et il est généralement chaud en juin        \n",
      "\n",
      "\n",
      "english:  the united states is sometimes beautiful during november and it is never rainy in march       \n",
      "french :  les états unis est parfois belle au mois de novembre et il est jamais pluvieux en mars    \n",
      "\n",
      "\n",
      "english:  new jersey is sometimes hot during march and it is beautiful in fall         \n",
      "french :  new jersey est parfois chaud en mars et il est beau à l' automne       \n",
      "\n",
      "\n",
      "english:  the grapefruit is our least favorite fruit but the orange is your least favorite        \n",
      "french :  le pamplemousse est notre fruit préféré moins mais l'orange est votre préféré moins        \n",
      "\n",
      "\n",
      "english:  i like grapefruit limes and pears                \n",
      "french :  i comme le pamplemousse citrons verts et les poires            \n",
      "\n",
      "\n",
      "english:  she dislikes lemons strawberries and grapes                \n",
      "french :  elle déteste les citrons les fraises et les raisins            \n",
      "\n",
      "\n",
      "english:  paris is usually chilly during fall but it is sometimes rainy in july         \n",
      "french :  paris est généralement froid à l'automne mais il est parfois pluvieux en juillet        \n",
      "\n",
      "\n",
      "english:  she likes mangoes apples and bananas                \n",
      "french :  elle aime les mangues les pommes et les bananes            \n",
      "\n",
      "\n",
      "english:  she is driving the old yellow truck               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "french :  elle conduit le vieux camion jaune               \n",
      "\n",
      "\n",
      "english:  we like peaches mangoes and oranges                \n",
      "french :  nous aimons les pêches les mangues et les oranges            \n",
      "\n",
      "\n",
      "english:  new jersey is usually quiet during fall but it is usually warm in april        \n",
      "french :  new jersey est généralement calme au cours de l' automne mais il est généralement chaud en avril    \n",
      "\n",
      "\n",
      "english:  california is never rainy during winter and it is usually mild in summer         \n",
      "french :  california est jamais pluvieux pendant l' hiver et il est généralement doux en été       \n",
      "\n",
      "\n",
      "english:  california is sometimes cold during winter but it is sometimes chilly in autumn         \n",
      "french :  california est parfois froid pendant l' hiver mais il est parfois frisquet à l' automne      \n",
      "\n",
      "\n",
      "english:  she likes lemons pears and oranges                \n",
      "french :  elle aime les citrons les poires et les oranges            \n",
      "\n",
      "\n",
      "english:  we like strawberries bananas and oranges                \n",
      "french :  nous aimons les fraises les bananes et les oranges            \n",
      "\n",
      "\n",
      "english:  india is never snowy during september but it is sometimes dry in spring         \n",
      "french :  l' inde est jamais de neige au mois de septembre mais il est parfois sec au printemps    \n",
      "\n",
      "\n",
      "english:  india is sometimes rainy during january and it is pleasant in february          \n",
      "french :  l' inde est parfois pluvieux en janvier et il est agréable en février        \n",
      "\n",
      "\n",
      "english:  paris is never relaxing during march but it is usually freezing in autumn         \n",
      "french :  paris est jamais relaxant au mois de mars mais il gèle habituellement à l' automne      \n",
      "\n",
      "\n",
      "english:  india is chilly during summer and it is sometimes beautiful in september          \n",
      "french :  l' inde est froid pendant l' été et il est parfois beau en septembre       \n",
      "\n",
      "\n",
      "english:  she likes peaches limes and mangoes                \n",
      "french :  elle aime les pêches citrons verts et les mangues            \n",
      "\n",
      "\n",
      "english:  india is never chilly during october but it is usually relaxing in november         \n",
      "french :  l' inde est jamais froid en octobre mais il est relaxant habituellement en novembre       \n",
      "\n",
      "\n",
      "english:  i like peaches grapes and lemons                \n",
      "french :  j'aime les pêches les raisins et les citrons             \n",
      "\n",
      "\n",
      "english:  she likes mangoes grapefruit and pears                \n",
      "french :  elle aime la mangue le pamplemousse et les poires            \n",
      "\n",
      "\n",
      "english:  the united states is usually dry during winter but it is sometimes snowy in february       \n",
      "french :  les états unis est généralement sec pendant l' hiver mais il est parfois enneigée en février     \n",
      "\n",
      "\n",
      "english:  china is usually nice during april and it is never snowy in august         \n",
      "french :  chine est généralement agréable en avril et il est jamais de neige en août       \n",
      "\n",
      "\n",
      "english:  she dislikes oranges and grapefruit                 \n",
      "french :  elle déteste les oranges et le pamplemousse              \n",
      "\n",
      "\n",
      "english:  paris is sometimes wonderful during autumn and it is warm in november          \n",
      "french :  paris est parfois merveilleux au cours de l' est et il est chaud en novembre      \n",
      "\n",
      "\n",
      "english:  the grapefruit is her least favorite fruit but the banana is their least favorite        \n",
      "french :  le pamplemousse est son fruit préféré moins mais la banane est leur moins préférée       \n",
      "\n",
      "\n",
      "english:  the grapefruit is his least liked fruit but the grape is my least liked        \n",
      "french :  le pamplemousse est son moins aimé des fruits mais le raisin est mon moins aimé      \n",
      "\n",
      "\n",
      "english:  paris is never busy during summer but it is never freezing in november         \n",
      "french :  paris est jamais occupé pendant l' été mais il gèle jamais en novembre        \n",
      "\n",
      "\n",
      "english:  china is sometimes pleasant during march but it is usually nice in may         \n",
      "french :  la chine est parfois agréable au mois de mars mais il est généralement agréable en mai     \n",
      "\n",
      "\n",
      "english:  india is sometimes cold during march but it is sometimes hot in january         \n",
      "french :  l' inde est parfois froid au mois de mars mais il est parfois chaud       \n",
      "\n",
      "\n",
      "english:  new jersey is rainy during june and it is sometimes nice in november         \n",
      "french :  new jersey est pluvieux en juin et il est parfois agréable en novembre        \n",
      "\n",
      "\n",
      "english:  the strawberry is his least favorite fruit but the peach is our least favorite        \n",
      "french :  la fraise est son fruit préféré moins mais la pêche est notre moins préféré       \n",
      "\n",
      "\n",
      "english:  paris is usually snowy during winter and it is sometimes beautiful in august         \n",
      "french :  paris est généralement enneigée en hiver et il est parfois beau en août        \n",
      "\n",
      "\n",
      "english:  france is never chilly during march and it is wet in april          \n",
      "french :  la france est jamais froid en mars et il est humide en avril        \n",
      "\n",
      "\n",
      "english:  their least liked fruit is the banana but her least liked is the peach        \n",
      "french :  leur fruit est moins aimé la banane mais elle est moins aimé la pêche       \n",
      "\n",
      "\n",
      "english:  china is cold during fall but it is usually relaxing in november          \n",
      "french :  chine est froid à l'automne mais il est relaxant habituellement en novembre         \n",
      "\n",
      "\n",
      "english:  new jersey is usually beautiful during april and it is never relaxing in december        \n",
      "french :  new jersey est généralement beau en avril et il est jamais relaxant en décembre       \n",
      "\n",
      "\n",
      "english:  he dislikes grapefruit mangoes and lemons                \n",
      "french :  il aime pas pamplemousse et mangues mangues              \n",
      "\n",
      "\n",
      "english:  new jersey is usually freezing during november but it is usually relaxing in autumn        \n",
      "french :  new jersey est le gel habituellement au mois de novembre mais il est relaxant habituellement à l' automne   \n",
      "\n",
      "\n",
      "english:  the strawberry is my most loved fruit but the lemon is her most loved        \n",
      "french :  la fraise est mon fruit le plus cher mais le citron elle est le plus aimé     \n",
      "\n",
      "\n",
      "english:  paris is sometimes pleasant during autumn and it is wonderful in september          \n",
      "french :  paris est parfois agréable au cours de l' automne et il est merveilleux en septembre      \n",
      "\n",
      "\n",
      "english:  her most loved fruit is the lemon but your most loved is the mango        \n",
      "french :  son fruit le plus aimé est le citron mais votre plus aimé est la mangue      \n",
      "\n",
      "\n",
      "english:  the mango is your least liked fruit but the apple is his least liked        \n",
      "french :  la mangue est votre fruit moins aimé mais la pomme est son moins aimé       \n",
      "\n",
      "\n",
      "english:  the pear is my most loved fruit but the lemon is his most loved        \n",
      "french :  la poire est mon fruit le plus cher mais le citron est le plus aimé      \n",
      "\n",
      "\n",
      "english:  he drives a new blue car                \n",
      "french :  il conduit une nouvelle voiture bleue               \n",
      "\n",
      "\n",
      "english:  the united states is warm during spring but it is wet in august         \n",
      "french :  les états unis est chaud au printemps mais il est humide en août        \n",
      "\n",
      "\n",
      "english:  paris is usually freezing during october and it is usually nice in april         \n",
      "french :  paris est le gel habituellement en octobre et il est généralement agréable en avril       \n",
      "\n",
      "\n",
      "english:  the peach is your most loved fruit but the banana is my most loved        \n",
      "french :  la pêche est votre fruit le plus aimé mais la banane est mon plus aimé      \n",
      "\n",
      "\n",
      "english:  you like grapes peaches and strawberries                \n",
      "french :  vous aimez les raisins les pêches et les fraises            \n",
      "\n",
      "\n",
      "english:  new jersey is sometimes nice during winter but it is hot in spring         \n",
      "french :  new jersey est parfois agréable pendant l' hiver mais il est chaud au printemps       \n",
      "\n",
      "\n",
      "english:  paris is usually beautiful during september but it is usually busy in spring         \n",
      "french :  paris est généralement beau au mois de septembre est il est généralement occupé au printemps      \n",
      "\n",
      "\n",
      "english:  china is usually snowy during autumn but it is usually hot in may         \n",
      "french :  chine est généralement enneigée en automne mais il est généralement chaud en mai        \n",
      "\n",
      "\n",
      "english:  that bird is her most feared animal               \n",
      "french :  cet oiseau est l'animal le plus redouté              \n",
      "\n",
      "\n",
      "english:  she dislikes apples peaches and bananas                \n",
      "french :  elle déteste les pommes les pêches et les bananes            \n",
      "\n",
      "\n",
      "english:  i plan to visit california next october               \n",
      "french :  je prévois de visiter la californie en octobre prochain            \n",
      "\n",
      "\n",
      "english:  you like limes bananas and grapefruit                \n",
      "french :  vous aimez citrons verts les bananes et le pamplemousse            \n",
      "\n",
      "\n",
      "english:  paris is never quiet during spring but it is usually hot in march         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "french :  paris est jamais tranquille au printemps mais il est généralement chaud en mars        \n",
      "\n",
      "\n",
      "english:  paris is rainy during winter and it is sometimes warm in april          \n",
      "french :  paris est pluvieux pendant l' hiver et il est parfois chaud en avril        \n",
      "\n",
      "\n",
      "english:  you like pears grapefruit and limes                \n",
      "french :  vous aimez les poires les pamplemousses et citrons verts            \n",
      "\n",
      "\n",
      "english:  paris is warm during january and it is rainy in october           \n",
      "french :  paris est chaud en cours et il pleut il pleut           \n",
      "\n",
      "\n",
      "english:  france is sometimes quiet during december and it is never snowy in january         \n",
      "french :  la france est parfois calme en décembre et il est jamais de neige en janvier      \n",
      "\n",
      "\n",
      "english:  paris is sometimes relaxing during summer but it is usually mild in november         \n",
      "french :  paris est relaxant parfois pendant l' été mais il est généralement doux en novembre       \n",
      "\n",
      "\n",
      "english:  she likes bananas and grapes                 \n",
      "french :  elle aime les bananes et les raisins              \n",
      "\n",
      "\n",
      "english:  the lime is her least liked fruit but the orange is his least liked        \n",
      "french :  la chaux est son moins aimé des fruits mais l'orange est son moins aimé       \n",
      "\n",
      "\n",
      "english:  california is never hot during fall but it is usually relaxing in april         \n",
      "french :  californie est jamais chaud à l'automne mais il est relaxant habituellement en avril        \n",
      "\n",
      "\n",
      "english:  new jersey is busy during december and it is usually mild in august         \n",
      "french :  new jersey est occupé en décembre et il est généralement doux en août        \n",
      "\n",
      "\n",
      "english:  china is never mild during april and it is sometimes wet in spring         \n",
      "french :  chine est jamais doux en avril et il est parfois humide au printemps        \n",
      "\n",
      "\n",
      "english:  the united states is never snowy during february and it is usually pleasant in autumn       \n",
      "french :  les états unis est jamais de neige en février et il est généralement agréable à l' automne    \n",
      "\n",
      "\n",
      "english:  india is never dry during january and it is never hot in february         \n",
      "french :  l' inde est jamais à sec en janvier et il est jamais chaude en février      \n",
      "\n",
      "\n",
      "english:  paris is usually wonderful during autumn and it is busy in spring          \n",
      "french :  paris est généralement magnifique en automne et il est occupé au printemps         \n",
      "\n",
      "\n",
      "english:  he likes pears peaches and lemons                \n",
      "french :  il aime les poires les pêches et les citrons            \n",
      "\n",
      "\n",
      "english:  paris is never cold during october but it is relaxing in january          \n",
      "french :  paris ne fait jamais froid en octobre mais il est relaxant en janvier        \n",
      "\n",
      "\n",
      "english:  you like lemons grapes and bananas                \n",
      "french :  vous aimez les citrons les raisins et les bananes            \n",
      "\n",
      "\n",
      "english:  she drives that little red truck                \n",
      "french :  elle conduit ce petit camion rouge               \n",
      "\n",
      "\n",
      "english:  new jersey is pleasant during fall and it is usually freezing in winter         \n",
      "french :  new jersey est agréable à l'automne et il gèle habituellement en hiver         \n",
      "\n",
      "\n",
      "english:  paris is usually rainy during december and it is cold in winter          \n",
      "french :  paris est généralement pluvieux en décembre et il fait froid en hiver         \n",
      "\n",
      "\n",
      "english:  california is usually pleasant during september but it is usually freezing in autumn         \n",
      "french :  californie est généralement agréable en septembre mais il gèle habituellement à l' automne        \n",
      "\n",
      "\n",
      "english:  the pear is our least liked fruit but the orange is their least liked        \n",
      "french :  la poire est notre fruit moins aimé mais l'orange est leur moins aimé        \n",
      "\n",
      "\n",
      "english:  india is snowy during spring and it is never busy in january          \n",
      "french :  l' inde est la neige au printemps et il est jamais occupé en janvier       \n",
      "\n",
      "\n",
      "english:  i dislike strawberries mangoes and pears                \n",
      "french :  je n'aime les fraises les mangues et les poires            \n",
      "\n",
      "\n",
      "english:  california is never cold during march but it is hot in fall          \n",
      "french :  californie ne fait jamais froid au mois de mars mais il est chaud à l' automne     \n",
      "\n",
      "\n",
      "english:  china is sometimes chilly during march and it is sometimes quiet in june         \n",
      "french :  la chine est parfois froid en mars et il est parfois calme en juin       \n",
      "\n",
      "\n",
      "english:  her most loved fruit is the grapefruit but your most loved is the orange        \n",
      "french :  son fruit le plus aimé est le pamplemousse mais votre plus aimé est l'orange       \n",
      "\n",
      "\n",
      "english:  the peach is her favorite fruit but the apple is my favorite          \n",
      "french :  la pêche est son fruit préféré mais la pomme est mon préféré         \n",
      "\n",
      "\n",
      "english:  paris is usually beautiful during may and it is never wonderful in june         \n",
      "french :  paris est généralement beau au mois de mai et il est jamais merveilleux en juin      \n",
      "\n",
      "\n",
      "english:  your least liked fruit is the mango but our least liked is the grapefruit        \n",
      "french :  votre fruit est moins aimé la mangue mais notre moins aimé est le pamplemousse       \n",
      "\n",
      "\n",
      "english:  the banana is their favorite fruit but the grapefruit is your favorite          \n",
      "french :  la banane est leur fruit préféré mais le pamplemousse est votre favori         \n",
      "\n",
      "\n",
      "english:  the grape is their least liked fruit but the strawberry is our least liked        \n",
      "french :  le raisin est leur fruit moins aimé mais la fraise est notre moins aimé       \n",
      "\n",
      "\n",
      "english:  the orange is his least favorite fruit but the banana is your least favorite        \n",
      "french :  l'orange est son fruit préféré moins mais la banane est votre préféré moins        \n",
      "\n",
      "\n",
      "english:  india is usually quiet during fall but it is sometimes pleasant in march         \n",
      "french :  l' inde est généralement calme au cours de l' automne mais il est parfois agréable en mars    \n",
      "\n",
      "\n",
      "english:  your most loved animals are horses                \n",
      "french :  vos animaux les plus aimés sont des chevaux             \n",
      "\n",
      "\n",
      "english:  i dislike peaches apples and strawberries                \n",
      "french :  je n'aime les les pêches les pommes et les fraises           \n",
      "\n",
      "\n",
      "english:  paris is sometimes busy during june and it is never quiet in fall         \n",
      "french :  paris est parfois occupé en juin et il est jamais tranquille à l' automne       \n",
      "\n",
      "\n",
      "english:  i like bananas lemons and grapes                \n",
      "french :  j'aime les bananes les citrons et les raisins             \n",
      "\n",
      "\n",
      "english:  you like apples grapefruit and limes                \n",
      "french :  vous aimez les pommes le pamplemousse et les citrons verts           \n",
      "\n",
      "\n",
      "english:  you dislike peaches mangoes and lemons                \n",
      "french :  vous n'aimez pas les pêches les mangues et citrons citrons           \n",
      "\n",
      "\n",
      "english:  we like oranges mangoes and bananas                \n",
      "french :  nous aimons les oranges les mangues et les bananes            \n",
      "\n",
      "\n",
      "english:  we dislike grapefruit mangoes and grapes                \n",
      "french :  nous détestons pamplemousses mangues mangues et les raisins             \n",
      "\n",
      "\n",
      "english:  new jersey is chilly during march but it is never nice in december         \n",
      "french :  new jersey est froid au mois de mars mais il est jamais agréable en décembre      \n",
      "\n",
      "\n",
      "english:  you dislike bananas mangoes and limes                \n",
      "french :  vous n'aimez pas les bananes les mangues et citrons verts           \n",
      "\n",
      "\n",
      "english:  he dislikes pears mangoes and strawberries                \n",
      "french :  il aime pas les poires les mangues et les fraises           \n",
      "\n",
      "\n",
      "english:  the united states is sometimes rainy during winter but it is never mild in april       \n",
      "french :  les états unis est parfois pluvieux pendant l' hiver mais il est jamais doux en avril     \n",
      "\n",
      "\n",
      "english:  i dislike grapefruit lemons and peaches                \n",
      "french :  je n'aime pamplemousses les citrons et les pêches             \n",
      "\n",
      "\n",
      "english:  paris is usually nice during june and it is sometimes quiet in autumn         \n",
      "french :  paris est généralement agréable en juin et il est parfois calme à l' automne       \n",
      "\n",
      "\n",
      "english:  you dislike oranges apples and grapefruit                \n",
      "french :  vous n'aimez pas les oranges les pommes et le pamplemousse           \n",
      "\n",
      "\n",
      "english:  new jersey is sometimes busy during july and it is sometimes warm in october        \n",
      "french :  new jersey est parfois occupé en juillet et il est parfois chaud en octobre       \n",
      "\n",
      "\n",
      "english:  california is sometimes chilly during winter but it is usually rainy in june         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "french :  californie est parfois froid pendant l' hiver mais il est généralement pluvieux en juin       \n",
      "\n",
      "\n",
      "english:  china is sometimes wet during august but it is never quiet in october         \n",
      "french :  chine est parfois humide au mois d' août mais il est jamais tranquille en octobre      \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    print(\"english: \", tokens_to_text(tmp_x[i:i+1], english_tokenizer).replace('<PAD>', ''))\n",
    "    prediction = model.predict(tmp_x[i:i+1])\n",
    "    print(\"french : \", logits_to_text(prediction[0], french_tokenizer).replace('<PAD>', ''))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction (IMPLEMENTATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: (137861, 21)\n",
      "output_sequence_length: 21\n",
      "english_vocab_size: 199\n",
      "french_vocab_size: 344\n",
      "\n",
      "\n",
      "input_seq.shape: (None, 21)\n",
      "embedding.shape: (None, 21, 256)\n",
      "Epoch 1/10\n",
      "862/862 [==============================] - 14s 17ms/step - loss: 1.3454 - accuracy: 0.6549 - val_loss: nan - val_accuracy: 0.7493\n",
      "Epoch 2/10\n",
      "862/862 [==============================] - 14s 16ms/step - loss: 0.6184 - accuracy: 0.8136 - val_loss: nan - val_accuracy: 0.8680\n",
      "Epoch 3/10\n",
      "862/862 [==============================] - 14s 16ms/step - loss: 0.3116 - accuracy: 0.9074 - val_loss: nan - val_accuracy: 0.9362\n",
      "Epoch 4/10\n",
      "862/862 [==============================] - 14s 17ms/step - loss: 0.1801 - accuracy: 0.9470 - val_loss: nan - val_accuracy: 0.9535\n",
      "Epoch 5/10\n",
      "862/862 [==============================] - 15s 17ms/step - loss: 0.1301 - accuracy: 0.9605 - val_loss: nan - val_accuracy: 0.9630\n",
      "Epoch 6/10\n",
      "862/862 [==============================] - 14s 17ms/step - loss: 0.1023 - accuracy: 0.9685 - val_loss: nan - val_accuracy: 0.9691\n",
      "Epoch 7/10\n",
      "862/862 [==============================] - 14s 16ms/step - loss: 0.0864 - accuracy: 0.9732 - val_loss: nan - val_accuracy: 0.9730\n",
      "Epoch 8/10\n",
      "862/862 [==============================] - 14s 17ms/step - loss: 0.0734 - accuracy: 0.9771 - val_loss: nan - val_accuracy: 0.9739\n",
      "Epoch 9/10\n",
      "862/862 [==============================] - 14s 17ms/step - loss: 0.0660 - accuracy: 0.9795 - val_loss: nan - val_accuracy: 0.9735\n",
      "Epoch 10/10\n",
      "862/862 [==============================] - 14s 17ms/step - loss: 0.0551 - accuracy: 0.9827 - val_loss: nan - val_accuracy: 0.9775\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 21) for input Tensor(\"input_32:0\", shape=(None, 21), dtype=float32), but it was called on an input with incompatible shape (2, 15).\n",
      "WARNING:tensorflow:5 out of the last 25 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa491496f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Sample 1:\n",
      "il a vu un vieux camion camion jaune <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Il a vu un vieux camion jaune\n",
      "Sample 2:\n",
      "new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "def final_predictions(x, y, x_tk, y_tk):\n",
    "    \"\"\"\n",
    "    Gets predictions using the final model\n",
    "    :param x: Preprocessed English data\n",
    "    :param y: Preprocessed French data\n",
    "    :param x_tk: English tokenizer\n",
    "    :param y_tk: French tokenizer\n",
    "    \"\"\"\n",
    "    # TODO: Train neural network using model_final\n",
    "    tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
    "    tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))\n",
    "\n",
    "    model = model_final(\n",
    "        tmp_x.shape,\n",
    "        max_french_sequence_length,\n",
    "        english_vocab_size,\n",
    "        french_vocab_size)\n",
    "    model.fit(tmp_x, preproc_french_sentences, batch_size=128, epochs=10, validation_split=0.2)\n",
    "    \n",
    "    ## DON'T EDIT ANYTHING BELOW THIS LINE\n",
    "    y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\n",
    "    y_id_to_word[0] = '<PAD>'\n",
    "\n",
    "    sentence = 'he saw a old yellow truck'\n",
    "    sentence = [x_tk.word_index[word] for word in sentence.split()]\n",
    "    sentence = pad_sequences([sentence], maxlen=x.shape[-1], padding='post')\n",
    "    sentences = np.array([sentence[0], x[0]])\n",
    "    predictions = model.predict(sentences, len(sentences))\n",
    "\n",
    "    print('Sample 1:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\n",
    "    print('Il a vu un vieux camion jaune')\n",
    "    print('Sample 2:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[1]]))\n",
    "    print(' '.join([y_id_to_word[np.max(x)] for x in y[0]]))\n",
    "\n",
    "\n",
    "final_predictions(preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "When you're ready to submit, complete the following steps:\n",
    "1. Review the [rubric](https://review.udacity.com/#!/rubrics/1004/view) to ensure your submission meets all requirements to pass\n",
    "2. Generate an HTML version of this notebook\n",
    "\n",
    "  - Run the next cell to attempt automatic generation (this is the recommended method in Workspaces)\n",
    "  - Navigate to **FILE -> Download as -> HTML (.html)**\n",
    "  - Manually generate a copy using `nbconvert` from your shell terminal\n",
    "```\n",
    "$ pip install nbconvert\n",
    "$ python -m nbconvert machine_translation.ipynb\n",
    "```\n",
    "  \n",
    "3. Submit the project\n",
    "\n",
    "  - If you are in a Workspace, simply click the \"Submit Project\" button (bottom towards the right)\n",
    "  \n",
    "  - Otherwise, add the following files into a zip archive and submit them \n",
    "  - `helper.py`\n",
    "  - `machine_translation.ipynb`\n",
    "  - `machine_translation.html`\n",
    "    - You can export the notebook by navigating to **File -> Download as -> HTML (.html)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the html\n",
    "\n",
    "**Save your notebook before running the next cell to generate the HTML output.** Then submit your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[NbConvertApp] Converting notebook machine_translation.ipynb to html',\n",
       " '[NbConvertApp] Writing 305996 bytes to machine_translation.html']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save before you run this cell!\n",
    "!!jupyter nbconvert *.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Enhancements\n",
    "\n",
    "This project focuses on learning various network architectures for machine translation, but we don't evaluate the models according to best practices by splitting the data into separate test & training sets -- so the model accuracy is overstated. Use the [`sklearn.model_selection.train_test_split()`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function to create separate training & test datasets, then retrain each of the models using only the training set and evaluate the prediction accuracy using the hold out test set. Does the \"best\" model change?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
